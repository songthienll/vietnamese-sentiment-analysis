import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from pyvi.ViTokenizer import ViTokenizer
import re
import os

st.set_page_config(page_title="Ph√¢n t√≠ch c·∫£m x√∫c m√≥n ƒÉn", page_icon="üçú", layout="wide")

# Load model v√† tokenizer
@st.cache_resource
def load_model_and_tokenizer():
    repo_id = 'songthienll/phobert-model'

    try:
        #Load tokenizer
        tokenizer = AutoTokenizer.from_pretrained(repo_id)

        #Load model
        model = AutoModelForSequenceClassification.from_pretrained(repo_id)
        model.eval()

        return tokenizer, model
        
    except Exception as e:
        st.error(f"Error loading model: {str(e)}")
        return None, None

# T·∫£i stopwords v√† h√†m lo·∫°i b·ªè stopwords
@st.cache_data
def load_stopwords():
    try:
        with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as f:
            vietnamese_stopwords = set(line.strip() for line in f)
        return vietnamese_stopwords
    except FileNotFoundError:
        st.warning("File vietnamese-stopwords.txt does not exist.")
        return set()

# Load model, tokenizer v√† stopwords
tokenizer, model = load_model_and_tokenizer()
vietnamese_stopwords = load_stopwords()

# ƒê·ªãnh nghƒ©a label
id2label = {0: "Ti√™u c·ª±c", 1: "T√≠ch c·ª±c"}

# H√†m ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
def preprocess_text(text):
    text = text.lower().strip()
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'[^a-zA-Z0-9\s\u00C0-\u1EF9]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def remove_stopwords(text):
    if not vietnamese_stopwords:
        return text
    return ' '.join([word for word in text.split() if word not in vietnamese_stopwords])

# H√†m tokenize vƒÉn b·∫£n
def tokenizer_text(text, tokenized=True, lowercased=True):
    text = preprocess_text(text)
    text = ViTokenizer.tokenize(text) if tokenized else text
    text = remove_stopwords(text)
    return text

# H√†m d·ª± ƒëo√°n sentiment
def predict_sentiment(text):
    if tokenizer is None or model is None:
        return "Error loading model", 0.0

    try:
        # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
        processed_text = tokenizer_text(text)
        # Tokenize
        inputs = tokenizer(processed_text, return_tensors="pt", padding=True, truncation=True, max_length=256)
        # D·ª± ƒëo√°n
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits

            # S·ª≠ d·ª•ng detach() ƒë·ªÉ tr√°nh l·ªói meta tensor
            logits = logits.detach()

            # D·ª± ƒëo√°n class
            predicted_class = torch.argmax(logits, dim=1).item()

            # T√≠nh x√°c su·∫•t
            probabilities = torch.softmax(logits, dim=1)
            confidence = probabilities[0][predicted_class].item()

        return id2label[predicted_class], confidence

    except Exception as e:
        st.error(f"L·ªói khi d·ª± ƒëo√°n: {str(e)}")
        return "L·ªói", 0.0

# Giao di·ªán Streamlit
st.markdown("<h1 style='text-align: center; white-space: nowrap;'>üçú Ph√¢n t√≠ch c·∫£m x√∫c ƒë√°nh gi√° m√≥n ƒÉn</h1>",unsafe_allow_html=True)
st.markdown("Nh·∫≠p ƒë√°nh gi√° v·ªÅ m√≥n ƒÉn ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c")
st.markdown("---")

# Ki·ªÉm tra xem model ƒë√£ load th√†nh c√¥ng ch∆∞a
if tokenizer is None or model is None:
    st.error("Kh√¥ng th·ªÉ load model. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n v√† file model.")
    st.stop()

user_input = st.text_area("ƒê√°nh gi√° c·ªßa b·∫°n:", height=150, placeholder="V√≠ d·ª•: 'Ph·ªü n√†y ngon tuy·ªát!'")

if st.button("Ph√¢n t√≠ch", key="analyze_button"):
    if user_input:
        with st.spinner("ƒêang ph√¢n t√≠ch..."):
            sentiment, confidence = predict_sentiment(user_input)

            if sentiment == "T√≠ch c·ª±c":
                st.success(f"**K·∫øt qu·∫£ Sentiment:** {sentiment} üòä")
                st.info(f"**ƒê·ªô tin c·∫≠y:** {confidence:.2%}")
            elif sentiment == "Ti√™u c·ª±c":
                st.error(f"**K·∫øt qu·∫£ Sentiment:** {sentiment} üòû")
                st.info(f"**ƒê·ªô tin c·∫≠y:** {confidence:.2%}")
            else:
                st.error(f"**K·∫øt qu·∫£:** {sentiment}")
    else:
        st.warning("Vui l√≤ng nh·∫≠p ƒë√°nh gi√° tr∆∞·ªõc khi ph√¢n t√≠ch!")

# Sidebar
st.sidebar.header("Th√¥ng tin ·ª©ng d·ª•ng")
st.sidebar.markdown("""
·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng model **PhoBERT** ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c c·ªßa c√°c ƒë√°nh gi√° v·ªÅ m√≥n ƒÉn Vi·ªát Nam.  
H√£y th·ª≠ nh·∫≠p m·ªôt c√¢u nh∆∞:  
- "B√°nh m√¨ n√†y qu√° ngon!"  
- "C∆°m t·∫•m h∆°i kh√¥."  
""")
st.sidebar.image("https://raw.githubusercontent.com/songthienll/vietnamese-sentiment-analysis/main/assets/food.jpeg", use_container_width=True)
